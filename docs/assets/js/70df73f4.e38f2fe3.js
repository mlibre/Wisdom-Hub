"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[341],{3905:(e,n,r)=>{r.d(n,{Zo:()=>s,kt:()=>f});var a=r(7294);function t(e,n,r){return n in e?Object.defineProperty(e,n,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[n]=r,e}function l(e,n){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),r.push.apply(r,a)}return r}function o(e){for(var n=1;n<arguments.length;n++){var r=null!=arguments[n]?arguments[n]:{};n%2?l(Object(r),!0).forEach((function(n){t(e,n,r[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):l(Object(r)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(r,n))}))}return e}function i(e,n){if(null==e)return{};var r,a,t=function(e,n){if(null==e)return{};var r,a,t={},l=Object.keys(e);for(a=0;a<l.length;a++)r=l[a],n.indexOf(r)>=0||(t[r]=e[r]);return t}(e,n);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)r=l[a],n.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(t[r]=e[r])}return t}var p=a.createContext({}),c=function(e){var n=a.useContext(p),r=n;return e&&(r="function"==typeof e?e(n):o(o({},n),e)),r},s=function(e){var n=c(e.components);return a.createElement(p.Provider,{value:n},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},d=a.forwardRef((function(e,n){var r=e.components,t=e.mdxType,l=e.originalType,p=e.parentName,s=i(e,["components","mdxType","originalType","parentName"]),u=c(r),d=t,f=u["".concat(p,".").concat(d)]||u[d]||m[d]||l;return r?a.createElement(f,o(o({ref:n},s),{},{components:r})):a.createElement(f,o({ref:n},s))}));function f(e,n){var r=arguments,t=n&&n.mdxType;if("string"==typeof e||t){var l=r.length,o=new Array(l);o[0]=d;var i={};for(var p in n)hasOwnProperty.call(n,p)&&(i[p]=n[p]);i.originalType=e,i[u]="string"==typeof e?e:t,o[1]=i;for(var c=2;c<l;c++)o[c]=r[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,r)}d.displayName="MDXCreateElement"},1138:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>p,contentTitle:()=>o,default:()=>m,frontMatter:()=>l,metadata:()=>i,toc:()=>c});var a=r(7462),t=(r(7294),r(3905));const l={sidebar_position:5,tags:["Linux","llama.cpp","offline","ai"]},o="llama.cpp",i={unversionedId:"ai/llamacpp",id:"ai/llamacpp",title:"llama.cpp",description:"Ollama is an open-source AI model server. It can get and run large language models (LLMs) locally on your machine.",source:"@site/docs/ai/llamacpp.md",sourceDirName:"ai",slug:"/ai/llamacpp",permalink:"/Wisdom-Hub/ai/llamacpp",draft:!1,tags:[{label:"Linux",permalink:"/Wisdom-Hub/tags/linux"},{label:"llama.cpp",permalink:"/Wisdom-Hub/tags/llama-cpp"},{label:"offline",permalink:"/Wisdom-Hub/tags/offline"},{label:"ai",permalink:"/Wisdom-Hub/tags/ai"}],version:"current",sidebarPosition:5,frontMatter:{sidebar_position:5,tags:["Linux","llama.cpp","offline","ai"]},sidebar:"tutorialSidebar",previous:{title:"AI",permalink:"/Wisdom-Hub/ai/"},next:{title:"Ollama",permalink:"/Wisdom-Hub/ai/ollama"}},p={},c=[{value:"Install",id:"install",level:2},{value:"Old GPUs",id:"old-gpus",level:2},{value:"Run",id:"run",level:2}],s={toc:c},u="wrapper";function m(e){let{components:n,...r}=e;return(0,t.kt)(u,(0,a.Z)({},s,r,{components:n,mdxType:"MDXLayout"}),(0,t.kt)("h1",{id:"llamacpp"},"llama.cpp"),(0,t.kt)("p",null,"Ollama is an open-source AI model server. It can get and run large language models (LLMs) locally on your machine."),(0,t.kt)("h2",{id:"install"},"Install"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-bash"},"sudo pacman -Syuu base-devel cmake gcc python3 rocm-hip-sdk rocm-opencl-sdk rocm-opencl-runtime rocm-ml-libraries rocm-device-libs\n\nsudo usermod -a -G render,video $(whoami)\nsudo reboot\nrocminfo\n\npamac install llama.cpp-hip\n")),(0,t.kt)("h2",{id:"old-gpus"},"Old GPUs"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-bash"},"# If you are using RDNA or RDNA 2 architecture like AMD Radeon RX 6500 XT, you may need to follow this step:\nsudo nano ~/.profile\n# Add the following lines:\nexport HSA_OVERRIDE_GFX_VERSION=10.3.0\nexport ROC_ENABLE_PRE_VEGA=1\nexport ROCM_PATH=/opt/rocm\nexport VLLM_USE_TRITON_FLASH_ATTN=0\nexport TORCH_USE_HIP_DSA=1\nexport HIP_VISIBLE_DEVICES=0\nexport PYTORCH_ROCM_ARCH=gfx1030\n")),(0,t.kt)("h2",{id:"run"},"Run"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-bash"},"llama-server -hf unsloth/GLM-4.7-Flash-GGUF:Q2_K_XL\n")))}m.isMDXComponent=!0}}]);
"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[5303],{3905:(t,e,n)=>{n.d(e,{Zo:()=>s,kt:()=>b});var a=n(7294);function i(t,e,n){return e in t?Object.defineProperty(t,e,{value:n,enumerable:!0,configurable:!0,writable:!0}):t[e]=n,t}function l(t,e){var n=Object.keys(t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(t);e&&(a=a.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),n.push.apply(n,a)}return n}function o(t){for(var e=1;e<arguments.length;e++){var n=null!=arguments[e]?arguments[e]:{};e%2?l(Object(n),!0).forEach((function(e){i(t,e,n[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(n,e))}))}return t}function r(t,e){if(null==t)return{};var n,a,i=function(t,e){if(null==t)return{};var n,a,i={},l=Object.keys(t);for(a=0;a<l.length;a++)n=l[a],e.indexOf(n)>=0||(i[n]=t[n]);return i}(t,e);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(t);for(a=0;a<l.length;a++)n=l[a],e.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(t,n)&&(i[n]=t[n])}return i}var c=a.createContext({}),p=function(t){var e=a.useContext(c),n=e;return t&&(n="function"==typeof t?t(e):o(o({},e),t)),n},s=function(t){var e=p(t.components);return a.createElement(c.Provider,{value:e},t.children)},m="mdxType",u={inlineCode:"code",wrapper:function(t){var e=t.children;return a.createElement(a.Fragment,{},e)}},h=a.forwardRef((function(t,e){var n=t.components,i=t.mdxType,l=t.originalType,c=t.parentName,s=r(t,["components","mdxType","originalType","parentName"]),m=p(n),h=i,b=m["".concat(c,".").concat(h)]||m[h]||u[h]||l;return n?a.createElement(b,o(o({ref:e},s),{},{components:n})):a.createElement(b,o({ref:e},s))}));function b(t,e){var n=arguments,i=e&&e.mdxType;if("string"==typeof t||i){var l=n.length,o=new Array(l);o[0]=h;var r={};for(var c in e)hasOwnProperty.call(e,c)&&(r[c]=e[c]);r.originalType=t,r[m]="string"==typeof t?t:i,o[1]=r;for(var p=2;p<l;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},4912:(t,e,n)=>{n.r(e),n.d(e,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>l,metadata:()=>r,toc:()=>p});var a=n(7462),i=(n(7294),n(3905));const l={sidebar_position:6,tags:["langchain","ai"]},o="Chat Uis",r={unversionedId:"ai/chat-ui",id:"ai/chat-ui",title:"Chat Uis",description:"Librechat",source:"@site/docs/ai/chat-ui.md",sourceDirName:"ai",slug:"/ai/chat-ui",permalink:"/Wisdom-Hub/ai/chat-ui",draft:!1,tags:[{label:"langchain",permalink:"/Wisdom-Hub/tags/langchain"},{label:"ai",permalink:"/Wisdom-Hub/tags/ai"}],version:"current",sidebarPosition:6,frontMatter:{sidebar_position:6,tags:["langchain","ai"]},sidebar:"tutorialSidebar",previous:{title:"Ollama",permalink:"/Wisdom-Hub/ai/ollama"},next:{title:"vllm",permalink:"/Wisdom-Hub/ai/vllm"}},c={},p=[{value:"Librechat",id:"librechat",level:2},{value:"https://github.com/mckaywrigley/chatbot-ui",id:"httpsgithubcommckaywrigleychatbot-ui",level:4},{value:"https://github.com/open-webui/open-webui",id:"httpsgithubcomopen-webuiopen-webui",level:4},{value:"https://github.com/huggingface/chat-ui",id:"httpsgithubcomhuggingfacechat-ui",level:4},{value:"https://github.com/nomic-ai/gpt4all",id:"httpsgithubcomnomic-aigpt4all",level:4},{value:"LobeChat",id:"lobechat",level:2}],s={toc:p},m="wrapper";function u(t){let{components:e,...n}=t;return(0,i.kt)(m,(0,a.Z)({},s,n,{components:e,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"chat-uis"},"Chat Uis"),(0,i.kt)("h2",{id:"librechat"},"Librechat"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'sudo pamac install mongodb-bin\nsudo systemctl enable mongodb.service\nsudo systemctl restart mongodb.service\nmongosh \'mongodb://localhost:27017\'\n\nsudo pacman -S meilisearch redis\nsudo systemctl enable redis\nsudo systemctl restart redis\nsudo systemctl enable meilisearch\nsudo systemctl restart meilisearch\n\ngit clone https://github.com/danny-avila/LibreChat.git --depth=1\ncd LibreChat\ncp .env.example .env\nnano .env\n# Comment PLUGIN_MODELS, GOOGLE_API_KEY, openAI and other providers to disable them\n# you may want to change ENDPOINTS variable and add ollama as well. not necessary\nRAG_API_URL=http://127.0.0.1:11434/v1/\nEMBEDDINGS_PROVIDER=ollama\nOLLAMA_BASE_URL=http://127.0.0.1:11434/v1/\nEMBEDDINGS_MODEL=mxbai-embed-large:latest\nDEBUG_RAG_API=true\n\nmv librechat.example.yaml librechat.yaml\n\ncustom:\n  - name: "Ollama"\n    apiKey: "ollama"\n    baseURL: "http://127.0.0.1:11434/v1/"\n    # or baseURL: "http://localhost:11434/v1/chat/completions" \n    models:\n      default: [\n        "llama3.1:8b"\n        ]\n      fetch: true\n    titleConvo: true\n    titleModel: "current_model"\nfileConfig:\n  endpoints:\n    custom:\n      fileLimit: 5\n      fileSizeLimit: 10  # Maximum size for an individual file in MB\n      totalSizeLimit: 50  # Maximum total size for all files in a single request in MB\n      supportedMimeTypes:\n        - "image/.*"\n        - "application/pdf"\n        - "application/text"\n        - "application/x-sh"\n        - "application/json"\n        - "application/javascript"\n        - "application/x-yaml"\n        - "application/x-shellscript"\n        - "application/text-plain"\n        - "text/plain"\n    default:\n      totalSizeLimit: 20\n      supportedMimeTypes:\n        - "image/.*"\n        - "application/pdf"\n        - "application/text"\n        - "application/x-sh"\n        - "application/json"\n        - "application/javascript"\n        - "application/x-yaml"\n        - "application/x-shellscript"\n        - "application/text-plain"\n        - "text/plain"\n  serverFileSizeLimit: 100  # Global server file size limit in MB\n  avatarSizeLimit: 2  # Limit for user avatar image size in MB\n\n# local rag still need wokr https://github.com/danny-avila/LibreChat/discussions/3293\nnpm ci\nnpm run frontend\nnpm run backend\n')),(0,i.kt)("h4",{id:"httpsgithubcommckaywrigleychatbot-ui"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/mckaywrigley/chatbot-ui"},"https://github.com/mckaywrigley/chatbot-ui")),(0,i.kt)("h4",{id:"httpsgithubcomopen-webuiopen-webui"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/open-webui/open-webui"},"https://github.com/open-webui/open-webui")),(0,i.kt)("h4",{id:"httpsgithubcomhuggingfacechat-ui"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/huggingface/chat-ui"},"https://github.com/huggingface/chat-ui")),(0,i.kt)("h4",{id:"httpsgithubcomnomic-aigpt4all"},(0,i.kt)("a",{parentName:"h4",href:"https://github.com/nomic-ai/gpt4all"},"https://github.com/nomic-ai/gpt4all")),(0,i.kt)("h2",{id:"lobechat"},"LobeChat"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"curl -fsSL https://ollama.com/install.sh | sh\nsudo systemctl enable ollama.service \nollama pull llama2\n\ncurl -fsSL https://get.pnpm.io/install.sh | sh -\ngit --depth 1 clone https://github.com/lobehub/lobe-chat.git\n# git fetch --unshallow \n# git pull --all\ncd lobe-chat\npnpm install\nmv .env.example .env\nOLLAMA_PROXY_URL=http://127.0.0.1:11434/v1\nOLLAMA_MODEL_LIST=llama2\n\npnpm dev\n")))}u.isMDXComponent=!0}}]);
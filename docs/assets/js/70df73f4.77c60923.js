"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[341],{3905:(e,n,a)=>{a.d(n,{Zo:()=>s,kt:()=>f});var r=a(7294);function t(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function l(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,r)}return a}function o(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?l(Object(a),!0).forEach((function(n){t(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function i(e,n){if(null==e)return{};var a,r,t=function(e,n){if(null==e)return{};var a,r,t={},l=Object.keys(e);for(r=0;r<l.length;r++)a=l[r],n.indexOf(a)>=0||(t[a]=e[a]);return t}(e,n);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(r=0;r<l.length;r++)a=l[r],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(t[a]=e[a])}return t}var p=r.createContext({}),c=function(e){var n=r.useContext(p),a=n;return e&&(a="function"==typeof e?e(n):o(o({},n),e)),a},s=function(e){var n=c(e.components);return r.createElement(p.Provider,{value:n},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},d=r.forwardRef((function(e,n){var a=e.components,t=e.mdxType,l=e.originalType,p=e.parentName,s=i(e,["components","mdxType","originalType","parentName"]),u=c(a),d=t,f=u["".concat(p,".").concat(d)]||u[d]||m[d]||l;return a?r.createElement(f,o(o({ref:n},s),{},{components:a})):r.createElement(f,o({ref:n},s))}));function f(e,n){var a=arguments,t=n&&n.mdxType;if("string"==typeof e||t){var l=a.length,o=new Array(l);o[0]=d;var i={};for(var p in n)hasOwnProperty.call(n,p)&&(i[p]=n[p]);i.originalType=e,i[u]="string"==typeof e?e:t,o[1]=i;for(var c=2;c<l;c++)o[c]=a[c];return r.createElement.apply(null,o)}return r.createElement.apply(null,a)}d.displayName="MDXCreateElement"},1138:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>p,contentTitle:()=>o,default:()=>m,frontMatter:()=>l,metadata:()=>i,toc:()=>c});var r=a(7462),t=(a(7294),a(3905));const l={sidebar_position:5,tags:["Linux","llama.cpp","offline","ai"]},o="llama.cpp",i={unversionedId:"ai/llamacpp",id:"ai/llamacpp",title:"llama.cpp",description:"Ollama is an open-source AI model server. It can get and run large language models (LLMs) locally on your machine.",source:"@site/docs/ai/llamacpp.md",sourceDirName:"ai",slug:"/ai/llamacpp",permalink:"/Wisdom-Hub/ai/llamacpp",draft:!1,tags:[{label:"Linux",permalink:"/Wisdom-Hub/tags/linux"},{label:"llama.cpp",permalink:"/Wisdom-Hub/tags/llama-cpp"},{label:"offline",permalink:"/Wisdom-Hub/tags/offline"},{label:"ai",permalink:"/Wisdom-Hub/tags/ai"}],version:"current",sidebarPosition:5,frontMatter:{sidebar_position:5,tags:["Linux","llama.cpp","offline","ai"]},sidebar:"tutorialSidebar",previous:{title:"AI",permalink:"/Wisdom-Hub/ai/"},next:{title:"Ollama",permalink:"/Wisdom-Hub/ai/ollama"}},p={},c=[{value:"Install",id:"install",level:2},{value:"Old GPUs",id:"old-gpus",level:2},{value:"Run",id:"run",level:2}],s={toc:c},u="wrapper";function m(e){let{components:n,...a}=e;return(0,t.kt)(u,(0,r.Z)({},s,a,{components:n,mdxType:"MDXLayout"}),(0,t.kt)("h1",{id:"llamacpp"},"llama.cpp"),(0,t.kt)("p",null,"Ollama is an open-source AI model server. It can get and run large language models (LLMs) locally on your machine."),(0,t.kt)("h2",{id:"install"},"Install"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-bash"},"sudo pacman -Syuu base-devel cmake gcc python3 rocm-hip-sdk rocm-opencl-sdk rocm-opencl-runtime rocm-ml-libraries rocm-device-libs\n\nsudo usermod -a -G render,video $(whoami)\nsudo reboot\nrocminfo\n\npamac install llama.cpp-bin\n# pamac install llama.cpp-hip\n# pamac install llama.cpp-vulkan-bin\n")),(0,t.kt)("h2",{id:"old-gpus"},"Old GPUs"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-bash"},"# If you are using RDNA or RDNA 2 architecture like AMD Radeon RX 6500 XT, you may need to follow this step:\n# Add the following lines:\nnano ~/.zshrc\nexport HSA_OVERRIDE_GFX_VERSION=10.3.0\nexport ROC_ENABLE_PRE_VEGA=1\nexport ROCM_PATH=/opt/rocm\nexport VLLM_USE_TRITON_FLASH_ATTN=0\nexport TORCH_USE_HIP_DSA=1\nexport HIP_VISIBLE_DEVICES=0\nexport PYTORCH_ROCM_ARCH=gfx1030\nsource .zshrc\n")),(0,t.kt)("h2",{id:"run"},"Run"),(0,t.kt)("pre",null,(0,t.kt)("code",{parentName:"pre",className:"language-bash"},"llama-server -hf unsloth/GLM-4.7-Flash-GGUF:Q2_K_XL\n")))}m.isMDXComponent=!0}}]);